<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>kafka | 变脸大师笔记</title><meta name="keywords" content="消息中间件,kafka"><meta name="author" content="fninging"><meta name="copyright" content="fninging"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Kafka[TOC] 一、概述1.定义 Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列，主要应用于大数据实时处理领域。 企业中常用的消息队列技术：activeMQ、rabbitMQ、rocketMQ、zeroMQ ​                                                    kafka ：对于数据的吞吐量大，适用于大数据领域  2.消息队列 MQ">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka">
<meta property="og:url" content="http://example.com/2021/08/29/Kafka/index.html">
<meta property="og:site_name" content="变脸大师笔记">
<meta property="og:description" content="Kafka[TOC] 一、概述1.定义 Kafka是一个分布式的基于发布&#x2F;订阅模式的消息队列，主要应用于大数据实时处理领域。 企业中常用的消息队列技术：activeMQ、rabbitMQ、rocketMQ、zeroMQ ​                                                    kafka ：对于数据的吞吐量大，适用于大数据领域  2.消息队列 MQ">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2021-08-29T09:35:41.000Z">
<meta property="article:modified_time" content="2021-08-29T10:11:00.053Z">
<meta property="article:author" content="fninging">
<meta property="article:tag" content="消息中间件">
<meta property="article:tag" content="kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/%E6%9C%88%E7%90%83.png"><link rel="canonical" href="http://example.com/2021/08/29/Kafka/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'kafka',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-08-29 18:11:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/kobe.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">变脸大师笔记</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">kafka</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-08-29T09:35:41.000Z" title="发表于 2021-08-29 17:35:41">2021-08-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-08-29T10:11:00.053Z" title="更新于 2021-08-29 18:11:00">2021-08-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/kafka/">kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="kafka"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><p>[TOC]</p>
<h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><h3 id="1-定义"><a href="#1-定义" class="headerlink" title="1.定义"></a>1.定义</h3><blockquote>
<p>Kafka是一个分布式的基于发布/订阅模式的<strong>消息队列，</strong>主要应用于大数据实时处理领域。</p>
<p>企业中常用的消息队列技术：activeMQ、rabbitMQ、rocketMQ、zeroMQ</p>
<p>​                                                    kafka ：对于数据的吞吐量大，适用于大数据领域</p>
</blockquote>
<h3 id="2-消息队列-MQ"><a href="#2-消息队列-MQ" class="headerlink" title="2.消息队列 MQ"></a>2.消息队列 MQ</h3><blockquote>
<p>MQ (message Queue) 在传统开发中的应用场景 : 发短信、秒杀等等</p>
</blockquote>
<p><img src="/2021/08/29/Kafka/1586852070311.png" alt="1586852070311"></p>
<h3 id="3-消息队列的两种模式"><a href="#3-消息队列的两种模式" class="headerlink" title="3.消息队列的两种模式"></a>3.消息队列的两种模式</h3><p>（1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）<br>​       消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。<br>​       消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。</p>
<p><img src="/2021/08/29/Kafka/1586846161208.png" alt="1586846161208"></p>
<p>（2）发布/订阅模式（一对多，消费者消费数据之后不会清除消息）<br>​        消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。</p>
<p><img src="/2021/08/29/Kafka/1586846187447.png" alt="1586846187447"></p>
<h3 id="4-Kafka基础架构"><a href="#4-Kafka基础架构" class="headerlink" title="4.Kafka基础架构"></a>4.Kafka基础架构</h3><p><img src="/2021/08/29/Kafka/1586684799520.png" alt="1586684799520"></p>
<p>1）Producer   ：消息生产者，就是向kafka broker发消息的客户端；</p>
<p>2）Consumer ：消息消费者，从kafka broker拉取消息的客户端；</p>
<p>3）Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>
<p>4）Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</p>
<p>5）Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic；</p>
<p>6）Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列；</p>
<p>7）Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。</p>
<p>8）leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</p>
<p>9）follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的follower。</p>
<h2 id="二、安装"><a href="#二、安装" class="headerlink" title="二、安装"></a>二、安装</h2><p>集群规划</p>
<table>
<thead>
<tr>
<th>kafka1</th>
<th>kafka2</th>
<th>kafka3</th>
</tr>
</thead>
<tbody><tr>
<td>zk</td>
<td>zk</td>
<td>zk</td>
</tr>
<tr>
<td>kafka</td>
<td>kafka</td>
<td>kafka</td>
</tr>
</tbody></table>
<p><a target="_blank" rel="noopener" href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a></p>
<p><img src="/2021/08/29/Kafka/1586685035658.png" alt="1586685035658"></p>
<p>安装步骤</p>
<p>0.准备工作 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">安装JDK,搭建zookeeper集群环境</span><br><span class="line">1) 解压zk安装</span><br><span class="line">[root@kafka1 opt]# tar -zxf zookeeper-3.4.6.tar.gz</span><br><span class="line">[root@kafka1 opt]# cd zookeeper-3.4.6/conf</span><br><span class="line">2) 修改conf下的zoo_sample.cfg文件名为zoo.cfg</span><br><span class="line">[root@kafka1 conf]# mv zoo_sample.cfg zoo.cfg</span><br><span class="line">3) 编辑zoo.cfg文件</span><br><span class="line">[root@kafka1 conf]# vi zoo.cfg</span><br><span class="line"><span class="meta">#</span><span class="bash">内容如下</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of milliseconds of each tick</span></span><br><span class="line">tickTime=2000</span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of ticks that the initial</span> </span><br><span class="line"><span class="meta">#</span><span class="bash"> synchronization phase can take</span></span><br><span class="line">initLimit=10</span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of ticks that can pass between</span> </span><br><span class="line"><span class="meta">#</span><span class="bash"> sending a request and getting an acknowledgement</span></span><br><span class="line">syncLimit=5</span><br><span class="line"><span class="meta">#</span><span class="bash"> the directory <span class="built_in">where</span> the snapshot is stored.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">do</span> not use /tmp <span class="keyword">for</span> storage, /tmp here is just</span> </span><br><span class="line"><span class="meta">#</span><span class="bash"> example sakes.</span></span><br><span class="line">dataDir=/opt/zookeeper-3.4.6/data</span><br><span class="line"><span class="meta">#</span><span class="bash"> the port at <span class="built_in">which</span> the clients will connect</span></span><br><span class="line">clientPort=2181</span><br><span class="line"></span><br><span class="line">server.1=kafka1:2888:3888</span><br><span class="line">server.2=kafka2:2888:3888</span><br><span class="line">server.3=kafka3:2888:3888</span><br><span class="line"><span class="meta">#</span><span class="bash">------------------------------------------------</span></span><br><span class="line">[root@kafka1 conf]# cd ..</span><br><span class="line">4) 在zookeeper下创建data目录，在data目录下创建myid文件</span><br><span class="line">[root@kafka1 zookeeper-3.4.6]# mkdir data</span><br><span class="line">[root@kafka1 zookeeper-3.4.6]# cd data</span><br><span class="line">[root@kafka1 data]# touch myid</span><br><span class="line">5) 在文件中写入数字和zoo.cfg配置的server.x这个x数字对应</span><br><span class="line">[root@kafka1 data]# echo 1 &gt;&gt; myid</span><br><span class="line">[root@kafka1 data]# cat myid</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">6) 回到zk根目录下，启动zookeeper</span><br><span class="line">[root@kafka1 zookeeper-3.4.6]# bin/zkServer.sh start</span><br><span class="line">[root@kafka1 zookeeper-3.4.6]# jps</span><br><span class="line">1233 Jps</span><br><span class="line">1215 QuorumPeerMain</span><br></pre></td></tr></table></figure>



<p>1.解压kafka安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 opt]# tar -zxvf kafka_2.11-0.11.0.0.tgz</span><br></pre></td></tr></table></figure>

<p>2.修改解压后的文件名</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 opt]# mv kafka_2.11-0.11.0.0  kafka</span><br></pre></td></tr></table></figure>

<p>3.在/opt/kafka目录下创建logs文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 opt]# cd kafka</span><br><span class="line">[root@kafka1 kafka]# mkdir logs</span><br></pre></td></tr></table></figure>

<p>4.修改配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]# cd config</span><br><span class="line">[root@kafka1 config]# vi server.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 每个kafka节点,broker.id必须不一样</span></span><br><span class="line">broker.id=0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 允许topic可以删除</span></span><br><span class="line">delete.topic.enable=true</span><br><span class="line"><span class="meta">#</span><span class="bash"> kafka运行日志存放的路径</span></span><br><span class="line">log.dirs=/opt/kafka/logs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置连接Zookeeper集群地址</span></span><br><span class="line">zookeeper.connect=kafka1:2181,kafka2:2181,kafka3:2181</span><br></pre></td></tr></table></figure>

<p>5.分发安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 opt]# scp -r /opt/kafka root@kafka2:/opt</span><br><span class="line">[root@kafka1 opt]# scp -r /opt/kafka root@kafka3:/opt</span><br></pre></td></tr></table></figure>

<p>6.分别在kafka2和kafka3上修改配置文件/opt/kafka/config/server.properties中的broker.id</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">broker.id=1</span><br><span class="line">broker.id=2</span><br><span class="line">注：broker.id不得重复</span><br></pre></td></tr></table></figure>

<p>7.启动集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在三台节点分别执行命令启动kafka</span><br><span class="line">[root@kafka1 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line">[root@kafka2 kafka]# bin/kafka-server-start.sh -daemon config/server.properties </span><br><span class="line">[root@kafka3 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br></pre></td></tr></table></figure>

<p>8.验证集群是否启动成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]# jps</span><br><span class="line">1571 Kafka</span><br><span class="line">1622 Jps</span><br><span class="line">1215 QuorumPeerMain</span><br></pre></td></tr></table></figure>

<p>8.关闭集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]$ bin/kafka-server-stop.sh stop</span><br><span class="line">[root@kafka2 kafka]$ bin/kafka-server-stop.sh stop</span><br><span class="line">[root@kafka3 kafka]$ bin/kafka-server-stop.sh stop</span><br></pre></td></tr></table></figure>





<h2 id="三、常用命令"><a href="#三、常用命令" class="headerlink" title="三、常用命令"></a>三、常用命令</h2><ol>
<li><p>创建topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]# bin/kafka-topics.sh  --zookeeper kafka1:2181  --create   --topic topica --partitions 3 --replication-factor 2</span><br></pre></td></tr></table></figure></li>
<li><p>查看所有topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]# bin/kafka-topics.sh  --zookeeper kafka1:2181  --list</span><br></pre></td></tr></table></figure></li>
<li><p>查看某个topic详情</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]# bin/kafka-topics.sh  --zookeeper kafka1:2181  --describe --topic topica</span><br></pre></td></tr></table></figure></li>
</ol>
<p>   <img src="/2021/08/29/Kafka/1586696472306.png" alt="1586696472306"></p>
<ol start="4">
<li><p>删除topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]# bin/kafka-topics.sh  --zookeeper kafka1:2181  --delete   --topic topica</span><br></pre></td></tr></table></figure></li>
<li><p>接收消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]# bin/kafka-console-consumer.sh --bootstrap-server kafka1:9092 --topic topica</span><br></pre></td></tr></table></figure></li>
<li><p>发送消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]# bin/kafka-console-producer.sh --broker-list      kafka1:9092 --topic topica</span><br></pre></td></tr></table></figure></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#对topic的操作  所以都是使用kafka-topics.sh命令</span><br><span class="line"># 针对topic的操作需要经过zk，所以--zookeeper</span><br><span class="line">bin/kafka-topics.sh --zookeeper node11:2181 --create  --topic topica --partitions 3 --replication-factor 3</span><br><span class="line">bin/kafka-topics.sh --zookeeper node11:2181 --list</span><br><span class="line">bin/kafka-topics.sh --zookeeper node11:2181 --describe --topic topica</span><br><span class="line">bin/kafka-topics.sh --zookeeper node11:2181 --delete  --topic topica</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>









<h2 id="四、Kafka-Java-API"><a href="#四、Kafka-Java-API" class="headerlink" title="四、Kafka Java API"></a>四、Kafka Java API</h2><h3 id="1-Producer-API"><a href="#1-Producer-API" class="headerlink" title="1.Producer API"></a>1.Producer API</h3><p>①  添加依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.11.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p>② 相关API</p>
<p><strong>KafkaProducer</strong>：需要创建一个生产者对象，用来发送数据</p>
<p><strong>ProducerConfig</strong>：获取所需的一系列配置参数</p>
<p><strong>ProducerRecord</strong>：每条数据都要封装成一个ProducerRecord对象</p>
<p>③ 异步发送 不带回调函数的Producer</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; configs = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;kafka1:9092&quot;</span>);</span><br><span class="line">        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class="line">        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String,String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(configs);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;topica&quot;</span>,<span class="string">&quot;hello&quot;</span>+i));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>相关参数：</strong></p>
<p><strong>batch.size</strong>：只有数据积累到batch.size之后，sender才会发送数据。默认值: 16384 (16kb)</p>
<p><strong>linger.ms</strong>：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。默认值:0 (0ms)</p>
<blockquote>
<p>以下两个参数，只有有一个触发了，send会发送消息</p>
<p>batch.size :  只有producer中积累16kb的数据才会发送</p>
<p>linger.ms: 如果数据量迟迟无法到达batch.size,根据发送的时间发送,默认值是0ms</p>
</blockquote>
<p>④ 异步发送 带回调函数的Producer</p>
<p>​    回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是RecordMetadata和Exception，如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。</p>
<p>注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer_CallBack</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; configs = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;kafka1:9092&quot;</span>);</span><br><span class="line">        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class="line">        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String,String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(configs);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;topica&quot;</span>, <span class="string">&quot;hello&quot;</span> + i), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(exception == <span class="keyword">null</span>)&#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;发送成功&quot;</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>⑤ 同步发送</p>
<p>​     同步发送的意思就是，一条消息发送之后，会阻塞当前线程，直至返回ack。</p>
<p>​       由于send方法返回的是一个Future对象，根据Futrue对象的特点，我们也可以实现同步发送的效果，只需在调用Future对象的get方发即可。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer_Synchronized</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; configs = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;kafka1:9092&quot;</span>);</span><br><span class="line">        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class="line">        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</span><br><span class="line">        <span class="comment">//设置消息在缓冲区(RecordAccumulator)的逗留时间,不设置无法感受同步的特点</span></span><br><span class="line">        configs.put(ProducerConfig.LINGER_MS_CONFIG,<span class="number">3000</span>);</span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String,String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(configs);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">            RecordMetadata metadata = producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">&quot;topica&quot;</span>, <span class="string">&quot;hello&quot;</span> + i)).get();</span><br><span class="line">            System.out.println(metadata);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="2-Consumer-API"><a href="#2-Consumer-API" class="headerlink" title="2.Consumer API"></a>2.Consumer API</h3><p>①  相关API</p>
<p><strong>KafkaConsumer</strong>：需要创建一个消费者对象，用来消费数据</p>
<p><strong>ConsumerConfig</strong>：获取所需的一系列配置参数</p>
<p><strong>ConsuemrRecord</strong>：每条数据都要封装成一个ConsumerRecord对象</p>
<p>② Consumer接收数据 </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Map&lt;String,Object&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        map.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;kafka1:9092&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);</span><br><span class="line">        map.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class);</span><br><span class="line">        map.put(ConsumerConfig.GROUP_ID_CONFIG,<span class="string">&quot;g1&quot;</span>);</span><br><span class="line"></span><br><span class="line">        KafkaConsumer&lt;String,String&gt; kafkaConsumer = <span class="keyword">new</span> KafkaConsumer(map);</span><br><span class="line">        kafkaConsumer.subscribe(Arrays.asList(<span class="string">&quot;topica&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>)&#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(<span class="number">100</span>);</span><br><span class="line">            Iterator&lt;ConsumerRecord&lt;String, String&gt;&gt; iterator = consumerRecords.iterator();</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="五、Kafka架构深入"><a href="#五、Kafka架构深入" class="headerlink" title="五、Kafka架构深入"></a>五、Kafka架构深入</h2><h3 id="1-Kafka工作流程及文件存储机制"><a href="#1-Kafka工作流程及文件存储机制" class="headerlink" title="1. Kafka工作流程及文件存储机制"></a>1. Kafka工作流程及文件存储机制</h3><p><img src="/2021/08/29/Kafka/1586769975957.png" alt="1586769975957"></p>
<p>Kafka中消息是以<strong>topic</strong>进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。</p>
<blockquote>
<p>kafka的工作流程</p>
<p>创建一个topic，需要指定分区和副本，分区理论上是无限多的，分布在broker上，副本的数量不能超过broker的数量(副本数量=leader个数 + follower个数)。</p>
<p>produer向topic中发送数据，数据存储在topic的partition中，首先写入leader这个分区副本，然后将数据</p>
<p>同步到follower中</p>
<p>consumer会从topic的partition中读取数据，也是从leader这个分区副本中读，</p>
<p>consumer会记录[offset偏移量]，offset代表当前consumer在分区中读取到哪个位置</p>
</blockquote>
<p>topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。<img src="/2021/08/29/Kafka/1586882320029.png" alt="1586882320029"></p>
<p>由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了<strong>分片</strong>和<strong>索引</strong>机制，将每个partition分为多个segment。每个segment对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">00000000000000000000.index</span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000028532124.index</span><br><span class="line">00000000000028532124.log</span><br></pre></td></tr></table></figure>

<p>index和log文件以当前segment的第一条消息的offset命名。下图为index文件和log文件的结构示意图。</p>
<p><img src="/2021/08/29/Kafka/1586777057482.png" alt="1586777057482"></p>
<p>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址。</p>
<p><img src="/2021/08/29/Kafka/1587888666088.png" alt="1587888666088"></p>
<h3 id="2-Kafka生产者-之-分区策略"><a href="#2-Kafka生产者-之-分区策略" class="headerlink" title="2. Kafka生产者 之 分区策略"></a>2. Kafka生产者 之 分区策略</h3><p>1）分区的原因</p>
<p>   （1）方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；</p>
<p>   （2）可以提高并发，因为可以以Partition为单位读写了。</p>
<p>2）分区的原则</p>
<p>​    我们需要将producer发送的数据封装成一个==ProducerRecord==对象。</p>
<p><img src="/2021/08/29/Kafka/1586777331146.png" alt="1586777331146"></p>
<p>  （1）指明 partition 的情况下，直接将指明的值直接作为 partiton 值；</p>
<p>  （2）没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；</p>
<p>  （3）既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//指定分区编号 </span></span><br><span class="line">ProducerRecord record = <span class="keyword">new</span> ProducerRecord(<span class="string">&quot;topica&quot;</span>,<span class="number">0</span>,<span class="keyword">null</span>,<span class="string">&quot;嘎嘎&quot;</span>+i);</span><br><span class="line"> <span class="comment">//指定key值</span></span><br><span class="line"> ProducerRecord record = <span class="keyword">new</span> ProducerRecord(<span class="string">&quot;topica&quot;</span>,<span class="string">&quot;key&quot;</span>,<span class="string">&quot;嘎嘎&quot;</span>+i);</span><br><span class="line"> <span class="comment">//指定value</span></span><br><span class="line"> ProducerRecord record = <span class="keyword">new</span> ProducerRecord(<span class="string">&quot;topica&quot;</span>,<span class="string">&quot;嘎嘎&quot;</span>+i);</span><br></pre></td></tr></table></figure>

<p><img src="/2021/08/29/Kafka/1587890450385.png" alt="1587890450385"></p>
<h3 id="3-Kafka生产者-之-数据可靠性保证"><a href="#3-Kafka生产者-之-数据可靠性保证" class="headerlink" title="3. Kafka生产者 之 数据可靠性保证"></a>3. Kafka生产者 之 数据可靠性保证</h3><p>​    为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。</p>
<p><strong>ack</strong>应答机制</p>
<p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等ISR中的follower全部接收成功。</p>
<p>所以Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</p>
<p><strong>acks</strong>参数配置：</p>
<p><strong>acks</strong>：</p>
<p>0：producer不等待broker的ack，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能<strong>丢失数据</strong>；</p>
<p>1：producer等待broker的ack，partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会<strong>丢失数据</strong>；</p>
<p>-1（all）：producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成<strong>数据重复</strong>。</p>
<p><img src="/2021/08/29/Kafka/1587892405492.png" alt="1587892405492"></p>
<h3 id="4-Kafka生产者-之-幂等性"><a href="#4-Kafka生产者-之-幂等性" class="headerlink" title="4. Kafka生产者 之 幂等性"></a>4. Kafka生产者 之 幂等性</h3><p>​    对于某些比较重要的消息，我们需要保证exactly once语义，即保证每条消息被发送且仅被发送一次。</p>
<p>在0.11版本(包含)之后，Kafka引入了幂等性机制（idempotent），配合acks = -1时的at least once语义，实现了producer到broker的exactly once语义。</p>
<p><strong>idempotent + at least once = exactly once</strong></p>
<p>使用时，只需将enable.idempotence属性设置为true，kafka自动将acks属性设为-1。</p>
<blockquote>
<p>对于一个事务做1次操作和n次操作，结果是一样  </p>
<p>数据库的【幂等性】：查询一定是幂等操作，增删改可能是幂等性操作，也可能不是</p>
<p>实际开发：希望xx功能可以保证幂等性操作 </p>
<p>​                    其实幂等性可以理解为表单重复提交,导致重复注册和重复下订单</p>
<p>kafka的幂等性：保证消息有且只有一条（不会丢失，也不会重复）</p>
</blockquote>
<p><img src="/2021/08/29/Kafka/1587959625826.png" alt="1587959625826"></p>
<h3 id="5-Kafka消费者-之-消费方式"><a href="#5-Kafka消费者-之-消费方式" class="headerlink" title="5. Kafka消费者 之 消费方式"></a>5. Kafka消费者 之 消费方式</h3><p>​    consumer采用pull（拉）模式从broker中读取数据。</p>
<p>​    push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。</p>
<p>​    pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout。</p>
<p><img src="/2021/08/29/Kafka/1587967874027.png" alt="1587967874027"></p>
<h3 id="6-Kafka消费者-之-分区分配策略"><a href="#6-Kafka消费者-之-分区分配策略" class="headerlink" title="6. Kafka消费者 之 分区分配策略"></a>6. Kafka消费者 之 分区分配策略</h3><p>​    一个consumer group中有多个consumer，一个 topic有多个partition，所以必然会涉及到partition的分配问题，即确定哪个partition由哪个consumer来消费。</p>
<p>Kafka有两种分配策略，一是roundrobin，一是range。</p>
<p>1）roundrobin</p>
<p>2）range</p>
<h3 id="7-Kafka消费者-之-offset的维护"><a href="#7-Kafka消费者-之-offset的维护" class="headerlink" title="7. Kafka消费者 之 offset的维护"></a>7. Kafka消费者 之 offset的维护</h3><p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</p>
<p>Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为**__consumer_offsets**。</p>
<p><img src="/2021/08/29/Kafka/1587970029749.png" alt="1587970029749"></p>
<p><img src="/2021/08/29/Kafka/1587971947385.png" alt="1587971947385"></p>
<h3 id="8-Kafka-高效读写数据"><a href="#8-Kafka-高效读写数据" class="headerlink" title="8. Kafka 高效读写数据"></a>8. Kafka 高效读写数据</h3><p>​    Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到到600M/s，而随机写只有100k/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p>
<h3 id="9-Zookeeper在Kafka中的作用"><a href="#9-Zookeeper在Kafka中的作用" class="headerlink" title="9. Zookeeper在Kafka中的作用"></a>9. Zookeeper在Kafka中的作用</h3><p>​     Kafka集群中有一个broker会被选举为Controller，负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。</p>
<p>Controller的管理工作都是依赖于Zookeeper的。</p>
<blockquote>
<p>kafka目前有意的简化zk在kafka中的作用，</p>
<p>目前存储的比较重要的信息 1. 可以使用的broker服务器 2. topic分区</p>
</blockquote>
<p>​      <img src="/2021/08/29/Kafka/1587972774773.png" alt="1587972774773"></p>
<p><img src="/2021/08/29/Kafka/1587972325367.png" alt="1587972325367"></p>
<h2 id="六、Flume整合Kafka"><a href="#六、Flume整合Kafka" class="headerlink" title="六、Flume整合Kafka"></a>六、Flume整合Kafka</h2><blockquote>
<p>大数据应用场景：flume 采集数据到kafka消息队列中，spark streaming消费数据，进而统计运算</p>
</blockquote>
<p>①. 在flume的job目录下新建exec-memory-kafka.conf文件</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="meta">a1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="meta">a1.sinks</span> = <span class="string">k1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">a1.sources.r1.type</span> = <span class="string">exec</span></span><br><span class="line"><span class="meta">a1.sources.r1.command</span> = <span class="string">tail -F /opt/a.log </span></span><br><span class="line"></span><br><span class="line"><span class="meta">a1.channels.c1.type</span> = <span class="string">memory</span></span><br><span class="line"></span><br><span class="line"><span class="meta">a1.sinks.k1.type</span> = <span class="string">org.apache.flume.sink.kafka.KafkaSink</span></span><br><span class="line"><span class="meta">a1.sinks.k1.kafka.topic</span> = <span class="string">topica</span></span><br><span class="line"><span class="meta">a1.sinks.k1.kafka.bootstrap.servers</span> = <span class="string">kafka1:9092,kafka2:9092,kafka3:9092</span></span><br><span class="line"></span><br><span class="line"><span class="meta">a1.sources.r1.channels</span> = <span class="string">c1</span></span><br><span class="line"><span class="meta">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br></pre></td></tr></table></figure>

<p>②. 启动kafka的consumer消费者</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]# bin/kafka-console-consumer.sh --bootstrap-server kafka1:9092 --topic topica</span><br></pre></td></tr></table></figure>

<p>③.启动flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@flume0 apache-flume-1.9.0-bin]# bin/flume-ng agent --conf conf --name a1 --conf-file job/exec-memory-kafka.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p>④.向a.log文件中追加数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@flume0 opt]# echo hello &gt;&gt; a.log</span><br></pre></td></tr></table></figure>

<p>⑤.查看kafka的consumer消费者的消费情况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@kafka1 kafka]# bin/kafka-console-consumer.sh --bootstrap-server kafka1:9092 --topic topica</span><br><span class="line">hello</span><br></pre></td></tr></table></figure>





<h2 id="七、Spring-Boot整合Kafka"><a href="#七、Spring-Boot整合Kafka" class="headerlink" title="七、Spring Boot整合Kafka"></a>七、Spring Boot整合Kafka</h2><p>① 添加springboot和kafka依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baizhi<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-test1<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-parent<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.5.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.11.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.5.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- kafka client处理 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p>② application.properties配置文件</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">server.port</span>=<span class="string">8888</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 生产者</span></span><br><span class="line"><span class="meta">spring.kafka.producer.bootstrap-servers</span>=<span class="string">kafka1:9092,kafka2:9092,kafka3:9092</span></span><br><span class="line"><span class="meta">spring.kafka.producer.key-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="meta">spring.kafka.producer.value-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># 消费者</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.bootstrap-servers</span>=<span class="string">kafka1:9092,kafka2:9092,kafka3:9092</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.key-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line"><span class="meta">spring.kafka.consumer.value-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br></pre></td></tr></table></figure>



<p>③ 测试类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.baizhi;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.annotation.KafkaListener;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.KafkaTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.EnableScheduling;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Scheduled;</span><br><span class="line"><span class="keyword">import</span> org.springframework.util.concurrent.ListenableFuture;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableScheduling</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Application</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaTemplate kafkaTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(Application.class,args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Scheduled(cron = &quot;0/1 * * * * ?&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">()</span></span>&#123;</span><br><span class="line">        String[] message=<span class="keyword">new</span> String[]&#123;<span class="string">&quot;this is a demo&quot;</span>,<span class="string">&quot;hello world&quot;</span>,<span class="string">&quot;hello boy&quot;</span>&#125;;</span><br><span class="line">        ListenableFuture future = kafkaTemplate.send(<span class="string">&quot;topica&quot;</span>, message[<span class="keyword">new</span> Random().nextInt(message.length)]);</span><br><span class="line">        future.addCallback(o -&gt; System.out.println(<span class="string">&quot;send-消息发送成功：&quot;</span> + message), throwable -&gt; System.out.println(<span class="string">&quot;消息发送失败：&quot;</span> + message));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &quot;topica&quot;,id=&quot;g1&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processMessage</span><span class="params">(ConsumerRecord&lt;?, ?&gt; record)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;record:&quot;</span>+record);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>





<p>定时器</p>
<p>springboot整合定时器</p>
<p>1.在启动上增加@EnableScheduling注解</p>
<p>2.在某个方法增加 @Scheduled(cron = “0/1 * * * * ?”)</p>
<p>作用：启动springboot项目，被@Scheduled注解标注的方法就会定时执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">@Scheduled(cron = &quot;cron表达式&quot;)</span><br><span class="line"></span><br><span class="line">cron表达式对应7个位置：秒 分  时  日期  月份  星期  年(可选)</span><br><span class="line">秒（Seconds）			 0~59的整数 </span><br><span class="line">分（Minutes）			 0~59的整数	 </span><br><span class="line">小时（Hours）			0~23的整数	 </span><br><span class="line">日期（DayofMonth）		1~31的整数（但是你需要考虑你月的天数） </span><br><span class="line">月份（Month）		    1~12的整数</span><br><span class="line">星期（DayofWeek）		1~7的整数</span><br><span class="line">年(可选，留空)（Year）	 1970~2099	 </span><br><span class="line"></span><br><span class="line">#日期和星期会冲突，只能同时指定一个 ,可以写成?代表不管</span><br><span class="line">5 5 5 10 6 ? 2019</span><br><span class="line">#年份省略，代表每年都会执行</span><br><span class="line">5 5 5 10 6 ?</span><br><span class="line">#*代表对应位置匹配任意时间</span><br><span class="line">* 5 5 10 6 ?    5点5分后每秒都会执行</span><br><span class="line"></span><br><span class="line">/：表示起始时间开始触发，然后每隔固定时间触发一次。例如在Minutes域使用5/20,则意味着5分钟触发一次，而25，45等分别触发一次. </span><br><span class="line">0/5  * * * * ?     每隔5秒触发一次</span><br><span class="line"></span><br><span class="line">-：表示范围。例如在Minutes域使用5-20，表示从5分到20分钟每分钟触发一次 </span><br><span class="line">0-5  * * * * ? </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



















</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">fninging</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2021/08/29/Kafka/">http://example.com/2021/08/29/Kafka/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">变脸大师笔记</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">消息中间件</a><a class="post-meta__tags" href="/tags/kafka/">kafka</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/08/29/Pagehelper/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">pagehelper</div></div></a></div><div class="next-post pull-right"><a href="/2021/08/29/SSM/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">ssm</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/kobe.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">fninging</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka"><span class="toc-number">1.</span> <span class="toc-text">Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A6%82%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">一、概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AE%9A%E4%B9%89"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-MQ"><span class="toc-number">1.1.2.</span> <span class="toc-text">2.消息队列 MQ</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.1.3.</span> <span class="toc-text">3.消息队列的两种模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Kafka%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84"><span class="toc-number">1.1.4.</span> <span class="toc-text">4.Kafka基础架构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85"><span class="toc-number">1.2.</span> <span class="toc-text">二、安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">1.3.</span> <span class="toc-text">三、常用命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Kafka-Java-API"><span class="toc-number">1.4.</span> <span class="toc-text">四、Kafka Java API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Producer-API"><span class="toc-number">1.4.1.</span> <span class="toc-text">1.Producer API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Consumer-API"><span class="toc-number">1.4.2.</span> <span class="toc-text">2.Consumer API</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81Kafka%E6%9E%B6%E6%9E%84%E6%B7%B1%E5%85%A5"><span class="toc-number">1.5.</span> <span class="toc-text">五、Kafka架构深入</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Kafka%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E5%8F%8A%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6"><span class="toc-number">1.5.1.</span> <span class="toc-text">1. Kafka工作流程及文件存储机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Kafka%E7%94%9F%E4%BA%A7%E8%80%85-%E4%B9%8B-%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">1.5.2.</span> <span class="toc-text">2. Kafka生产者 之 分区策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Kafka%E7%94%9F%E4%BA%A7%E8%80%85-%E4%B9%8B-%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81"><span class="toc-number">1.5.3.</span> <span class="toc-text">3. Kafka生产者 之 数据可靠性保证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Kafka%E7%94%9F%E4%BA%A7%E8%80%85-%E4%B9%8B-%E5%B9%82%E7%AD%89%E6%80%A7"><span class="toc-number">1.5.4.</span> <span class="toc-text">4. Kafka生产者 之 幂等性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Kafka%E6%B6%88%E8%B4%B9%E8%80%85-%E4%B9%8B-%E6%B6%88%E8%B4%B9%E6%96%B9%E5%BC%8F"><span class="toc-number">1.5.5.</span> <span class="toc-text">5. Kafka消费者 之 消费方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-Kafka%E6%B6%88%E8%B4%B9%E8%80%85-%E4%B9%8B-%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-number">1.5.6.</span> <span class="toc-text">6. Kafka消费者 之 分区分配策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-Kafka%E6%B6%88%E8%B4%B9%E8%80%85-%E4%B9%8B-offset%E7%9A%84%E7%BB%B4%E6%8A%A4"><span class="toc-number">1.5.7.</span> <span class="toc-text">7. Kafka消费者 之 offset的维护</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-Kafka-%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE"><span class="toc-number">1.5.8.</span> <span class="toc-text">8. Kafka 高效读写数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-Zookeeper%E5%9C%A8Kafka%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">1.5.9.</span> <span class="toc-text">9. Zookeeper在Kafka中的作用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81Flume%E6%95%B4%E5%90%88Kafka"><span class="toc-number">1.6.</span> <span class="toc-text">六、Flume整合Kafka</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81Spring-Boot%E6%95%B4%E5%90%88Kafka"><span class="toc-number">1.7.</span> <span class="toc-text">七、Spring Boot整合Kafka</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/08/29/Pagehelper/" title="pagehelper"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="pagehelper"/></a><div class="content"><a class="title" href="/2021/08/29/Pagehelper/" title="pagehelper">pagehelper</a><time datetime="2021-08-29T09:35:41.000Z" title="发表于 2021-08-29 17:35:41">2021-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/29/Kafka/" title="kafka"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="kafka"/></a><div class="content"><a class="title" href="/2021/08/29/Kafka/" title="kafka">kafka</a><time datetime="2021-08-29T09:35:41.000Z" title="发表于 2021-08-29 17:35:41">2021-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/29/SSM/" title="ssm"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ssm"/></a><div class="content"><a class="title" href="/2021/08/29/SSM/" title="ssm">ssm</a><time datetime="2021-08-29T09:35:41.000Z" title="发表于 2021-08-29 17:35:41">2021-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/29/MyBatis/" title="mybatis"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mybatis"/></a><div class="content"><a class="title" href="/2021/08/29/MyBatis/" title="mybatis">mybatis</a><time datetime="2021-08-29T09:35:41.000Z" title="发表于 2021-08-29 17:35:41">2021-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/29/Spring/" title="spring"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="spring"/></a><div class="content"><a class="title" href="/2021/08/29/Spring/" title="spring">spring</a><time datetime="2021-08-29T09:35:41.000Z" title="发表于 2021-08-29 17:35:41">2021-08-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By fninging</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>